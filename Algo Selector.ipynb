{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a1f1548-a352-4be6-8cd8-f808402284b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68aaa086-7fc9-46ae-833e-5a2cfe4aa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b97da881-bc86-4926-b0ee-bc92352a63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the last column is the target, adjust as needed\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "033bd9f9-f74e-4a07-8f25-8f047e466857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae235a91-f2a1-4096-bb81-66e1b342a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing steps: OneHotEncoder for categorical and StandardScaler for numeric features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['int64', 'float64']).columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b290bd7-3f5b-4ea1-8e4f-5d568020535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'SVM': SVC(kernel='rbf', probability=True),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100),\n",
    "    'k-NN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "193f2104-9ca7-4911-81d4-1c6757438609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model using cross-validation and additional metrics\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    # Create a pipeline that first transforms the data then fits the model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_proba = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "\n",
    "    # Store the results\n",
    "    results[model_name] = {\n",
    "        'Cross-Validation Mean Accuracy': np.mean(cv_scores),\n",
    "        'Test Set Accuracy': test_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "292d29de-511a-41a8-b214-f05371c965bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model based on evaluation metrics\n",
    "best_models = list(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4ddf19d-581f-457a-ab33-f5914c8b6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criteria list in order of evaluation\n",
    "criteria = ['Test Set Accuracy', 'Cross-Validation Mean Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f964fc99-030e-465f-91ef-74db5953f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the criteria to narrow down the best model(s)\n",
    "for criterion in criteria:\n",
    "    max_value = max(results[model][criterion] for model in best_models if results[model][criterion] is not None)\n",
    "    best_models = [model for model in best_models if results[model][criterion] == max_value]\n",
    "    if len(best_models) == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88a2c411-f97e-4ba9-afd2-bcf864f4c04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "  Cross-Validation Mean Accuracy: 0.98\n",
      "  Test Set Accuracy: 1.00\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-Score: 1.00\n",
      "  ROC-AUC: 1.00\n",
      "\n",
      "Random Forest:\n",
      "  Cross-Validation Mean Accuracy: 1.00\n",
      "  Test Set Accuracy: 1.00\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-Score: 1.00\n",
      "  ROC-AUC: 1.00\n",
      "\n",
      "Gradient Boosting:\n",
      "  Cross-Validation Mean Accuracy: 1.00\n",
      "  Test Set Accuracy: 1.00\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-Score: 1.00\n",
      "  ROC-AUC: 1.00\n",
      "\n",
      "k-NN:\n",
      "  Cross-Validation Mean Accuracy: 0.77\n",
      "  Test Set Accuracy: 0.75\n",
      "  Precision: 0.84\n",
      "  Recall: 0.75\n",
      "  F1-Score: 0.75\n",
      "  ROC-AUC: 0.90\n",
      "\n",
      "Neural Network:\n",
      "  Cross-Validation Mean Accuracy: 0.96\n",
      "  Test Set Accuracy: 0.95\n",
      "  Precision: 0.96\n",
      "  Recall: 0.95\n",
      "  F1-Score: 0.95\n",
      "  ROC-AUC: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.2f}\" if value is not None else f\"  {metric}: N/A\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59ab80a2-1faf-478f-94f9-fc61e878f72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Models (tie):\n",
      "  Random Forest\n",
      "  Test Set Accuracy: 1.00\n",
      "  Cross-Validation Mean Accuracy: 1.00\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-Score: 1.00\n",
      "  ROC-AUC: 1.00\n",
      "\n",
      "  Gradient Boosting\n",
      "  Test Set Accuracy: 1.00\n",
      "  Cross-Validation Mean Accuracy: 1.00\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-Score: 1.00\n",
      "  ROC-AUC: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the best model(s)\n",
    "if len(best_models) > 1:\n",
    "    print(\"Best Models (tie):\")\n",
    "else:\n",
    "    print(\"Best Model:\")\n",
    "\n",
    "for model in best_models:\n",
    "    print(f\"  {model}\")\n",
    "    print(f\"  Test Set Accuracy: {results[model]['Test Set Accuracy']:.2f}\")\n",
    "    print(f\"  Cross-Validation Mean Accuracy: {results[model]['Cross-Validation Mean Accuracy']:.2f}\")\n",
    "    print(f\"  Precision: {results[model]['Precision']:.2f}\")\n",
    "    print(f\"  Recall: {results[model]['Recall']:.2f}\")\n",
    "    print(f\"  F1-Score: {results[model]['F1-Score']:.2f}\")\n",
    "    print(f\"  ROC-AUC: {results[model]['ROC-AUC']:.2f}\" if results[model]['ROC-AUC'] is not None else \"  ROC-AUC: N/A\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
